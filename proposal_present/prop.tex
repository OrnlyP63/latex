\documentclass{beamer}
\usepackage{filecontents}



%construct dynamic page
\setbeamercovered{highly dynamic}
\newcounter{saveenumi}
\newcommand{\seti}{\setcounter{saveenumi}{\value{enumi}}}
\newcommand{\conti}{\setcounter{enumi}{\value{saveenumi}}}
\resetcounteronoverlays{saveenumi}

%set color and initial
\usetheme[progressbar=frametitle]{metropolis}
\definecolor{mygreen}{rgb}{.125,.5,.25}
\usecolortheme[named=mygreen]{structure}
\setbeamertemplate{frame numbering}[fraction]
\useoutertheme{metropolis}
\useinnertheme{metropolis}
\usefonttheme{metropolis}
\usecolortheme{spruce}
\setbeamercolor{background canvas}{bg=white}

\title{Ground Shaking Prediction}
\subtitle{with Graph Neural Network and Semi-Supervised Learning}
\author{Phiphat Chomchit}
\institute{Chiang Mai University}

\begin{document}
	% Fill color in block
	\metroset{block=fill}
	
	\begin{frame}
		\titlepage
	\end{frame}
	
	\begin{frame}[t]{Earthquake Warning}
		\centering
		\textbf{Ground Shaking Prediction.}
		\begin{itemize}
			\item Ground Motion Prediction Equations (GMPEs)
			\item Temporal and Spatial Prediction
			\item Imbalanced Data
		\end{itemize}
		\textbf{My work}
		\begin{itemize}
			\item Graph Convolutional Neural Network 
			\item Self-Supervised Learning
			\item Semi-Supervised Learning
		\end{itemize}
	\end{frame}

	\begin{frame}[t]{Why do we need machine learning?}
		\begin{enumerate}
			\item Seismic data
			\begin{itemize}
				\item Imbalanced Data
				\item Temporal and Spatial Data
			\end{itemize}
			\item Purpose of model
			\begin{itemize}
				\item rapid warning
				\item peak ground motion prediction
			\end{itemize}
		\end{enumerate}
		
		\begin{figure}
			\includegraphics[scale=0.5]{imb.png}
			\caption{seismic data are long tail data. (Dario, 2020)}
		\end{figure}
	\end{frame}
	\begin{frame}[t]{Basic Seismic Knowlendge}
		
		\begin{enumerate}
			\item \textbf{Earthquake} is the sudden fracture and movement of rocks inside the Earth.  Part of the energy released produces seismic waves.
			\seti
		\end{enumerate}
		\begin{figure}
			\centering
			\includegraphics[scale=0.5]{stick.jpg}
			\caption{stick-slip model (Santi Pailoplee, 2021)}
		\end{figure}
	\end{frame}

	\begin{frame}[t]{Basic Seismic Knowlendge}
		\begin{enumerate}
			\conti
			\item \textbf{Hypocenter} or Focus the point below the epicenter at which an earthquake
			begins.
			\item \textbf{Epicenter} the point (map location) on the Earthâ€™s surface directly above 
			the hypocenter or focus of an earthquake.
			\seti
		\end{enumerate}
		\begin{figure}
			\centering
			\includegraphics[scale=0.8]{velocity.jpg}
			\caption{Epicenter and Hypocenter (Santi Pailoplee, 2021)}
		\end{figure}
	\end{frame}

	\begin{frame}[t]{Basic Seismic Knowlendge}
		\begin{enumerate}
			\conti
			\item \textbf{P Wave} is the primary body wave; the first seismic wave detected by 
			seismographs; able to move through both liquid and solid rock. P wave is the fastest wave.
			
			\item \textbf{S Waves} is shear waves that are secondary body waves that oscillate the ground perpendicular to the direction of wave travel. 
			\seti
		\end{enumerate}
		\begin{figure}
			\centering
			\includegraphics[scale=0.6]{station.jpg}
			\caption{P-wave, S-wave and surface wave (Santi Pailoplee, 2021)}
		\end{figure}
	\end{frame}

		
	\begin{frame}[t]{Basic Seismic Knowlendge}
		\begin{enumerate}
			\conti
			\item \textbf{Peak Ground Acceleration} is a largest increase in velocity recorded by a particular station during 
			an earthquake. (Commonly called PGA) 
			\seti
		\end{enumerate}
		
		\begin{figure}
			\centering
			\includegraphics[scale=0.35]{pga.jpg}
			\caption{PGA, PGV, PGD (Santi Pailoplee, 2021)}
		\end{figure}
	\end{frame}
	
	\begin{frame}[t]{Basic Seismic Knowledge}
		\begin{enumerate}
			\conti
			\item \textbf{Attenuation} is decrease in wave size, or amplitude, away from source. When you 
			throw a pebble in a pond, it makes waves on the surface that move out from the place where 
			the pebble entered the water. The waves are largest where they are formed and get smaller as 
			they move away.
			\seti
		\end{enumerate}
	
		\begin{figure}
			\includegraphics[scale=0.35]{anu.jpg}
			\caption{Attenuation (Santi Pailoplee, 2021)}
		\end{figure}
	\end{frame}

	\begin{frame}[t]{Basic Seismic Knowledge}
		\begin{enumerate}
			\conti
			\item \textbf{Ground motion prediction model (GMPEs)}, also called ground-motion models 
			(GMMs) and attenuation relations, estimate the shaking (strong ground motion) that may occur 
			at a site if an earthquake of a certain magnitude occurs at a nearby location.
			\seti
		\end{enumerate}
		
		\begin{figure}
			\centering
			\includegraphics[scale=0.5]{shak.jpg}
			\caption{Ground Shaking (Santi Pailoplee, 2021)}
		\end{figure}
	\end{frame}
	
	\begin{frame}[t]{Basic Seismic Knowlendge}
		\begin{enumerate}
			\conti
			\item \textbf{ShakeMap} The system is designed to combine instrumental measurements with information about \textbf{local seismic site conditions} and \textbf{the earthquake source} to estimate continuous shaking variations throughout a spatial area

		\end{enumerate}
		\begin{figure}
			\centering
			\includegraphics[scale=0.5]{example.png}
			\caption{ShakeMap(USGS, 2018)}
		\end{figure}
		
	\end{frame}

	\begin{frame}[t]{Review Papers}
		Why do we need machine learning?\\
		
		\vspace{10pt}
		\begin{enumerate}
			\item Parameters
			\begin{enumerate}
				\item Multilayer Perceptron
				\item Hybrid GMPE

			\end{enumerate}
			\vspace{10pt}
			\item Waveform
			\begin{enumerate}
				\item Multilayer Perceptron
				\item Convolutional Neural Network
				\item Graph Neural Network
				\item Self Supervised Learning
			\end{enumerate}
		\end{enumerate}
	\end{frame}
	


	\begin{frame}[t]{Multilayer Perceptron}
		\begin{figure}
			\includegraphics[scale=0.4]{mlp.png}
			\caption{PGA prediction with ANN (Derras, 2014)}
		\end{figure}
		
	\end{frame}
	
	\begin{frame}[t]{Hybrid}
		\begin{figure}
			\includegraphics[scale=0.5]{hybrid.png}
			\caption{Hybrid model(GMPE + ERT) (Hisahiko, 2020)}
		\end{figure}
	\end{frame}
	
	
	\begin{frame}[t]{Convolutional Neural Network}
		\begin{figure}
			\includegraphics[scale=0.3]{cnn.png}
			\caption{CNN for rapid earthquake warning (Dario, 2020)}
		\end{figure}
	\end{frame}
	

	
	\begin{frame}[t]{Graph Neural Network}
		\begin{figure}
			\includegraphics[scale=0.3]{gnn.png}
			\caption{Characterize source of earthquake with GNN (M. P. A. van den Ende, 2020)}
		\end{figure}
	\end{frame}
	
	\begin{frame}[t]{Focus on my work}
		\begin{enumerate}
			\item Graph Neural Network
				\begin{itemize}
					\item spatial model
					\item temporal model
					\item static graph, dynamic signal
				\end{itemize}
			\item Semi-Supervised Learning and Self-Supervised Learning
				\begin{itemize}
					\item Unlabeled data
					\item Imbalanced data
				\end{itemize}
		\end{enumerate}
		
	\end{frame}
		\begin{frame}[t]{Focus on my work}
		\section{Graph Neural Network.}
		\begin{figure}
			\includegraphics[scale=0.3]{node.png}
		\end{figure}
	\end{frame}

	\begin{frame}[t]{What is Graph Neural Network?}\vspace{10pt}
	
	\begin{block}{Graph definition}
		A graph $\mathcal{G}$ is defined as a tuple of a set of nodes/vertices $V$, and a set of edges /links $E$: $\mathcal{G}=(V,E)$. Each edge is a pair of two vertices, and represents a connection between them. 
	\end{block}
	For instance, let's look at the following graph:
	\begin{figure}
		\centering
		\includegraphics[scale=0.5]{sg.png}
		\caption{Example graph}
	\end{figure}
	
	The vertices are $V=\{1,2,3,4\}$,\\ and edges $E=\{(1,2), (2,3), (2,4), (3,4)\}$.
	\end{frame}

	\begin{frame}[t]{What is Graph Neural Network?}\vspace{4pt}
	\begin{block}{Definition of Adjacency Matrix}
		\vspace{0.5em}
		The \textbf{adjacency matrix} $A$ is a square matrix whose elements indicate whether pairs of vertices are adjacent, i.e. connected, or not. In the simplest case, $A_{ij}$ is 1 if there is a connection from node $i$ to $j$, and otherwise 0.
		\vspace{0.5em}
	\end{block}
	
	$$
	A = \begin{bmatrix}
		0 & 1 & 0 & 0\\
		1 & 0 & 1 & 1\\
		0 & 1 & 0 & 1\\
		0 & 1 & 1 & 0
	\end{bmatrix}
	$$
	
	keep in mind that $A$ is a symmetric matrix ($A_{ij}=A_{ji}$)
	\end{frame}

	\begin{frame}[t]{Graph Convolutions}\vspace{4pt}
	\begin{enumerate}
		\item GCNs are similar to convolutions in images in the sense that the "filter" parameters are typically shared over all locations in the graph. 
		\item At the same time, GCNs rely on message passing methods, which means that vertices exchange information with the neighbors, and send "messages" to each other.
	\end{enumerate}
	
	\begin{figure}
		\centering
		\includegraphics[scale=0.4]{sg2.png}
		\caption{Message passing between nodes}
	\end{figure}
	\end{frame}

	\begin{frame}[t]{Graph Convolutions}\vspace{4pt}
	Given the previous features of nodes $H^{(l)}$, the GCN layer is defined as follows:
	
	$$H^{(l+1)} = \sigma\left(\hat{D}^{-1/2}\hat{A}\hat{D}^{-1/2}H^{(l)}W^{(l)}\right)$$
	\begin{enumerate}
		\item $W^{(l)}$ is the weight parameters with which we transform the input features into messages ($H^{(l)}W^{(l)}$). 
		\item To the adjacency matrix $A$ we add the identity matrix so that each node sends its own message also to itself: $\hat{A}=A+I$. 
		\item $\hat{D}$ which is a diagonal matrix with $D_{ii}$ denoting the number of neighbors node $i$ has. 
		\item $\sigma$ represents an arbitrary activation function.
	\end{enumerate}
	\end{frame}

	\begin{frame}[t]{Focus on my work}
		\section{Semi-Supervised Learning and Self-Supervised Learning.}
	\end{frame}	

	\begin{frame}[t]{Self Supervised Learning?}\vspace{10pt}
		
		Contrastive self-supervised learning has outperformed supervised pretraining on many downstream tasks like segmentation and object detection.
		
		What if we can get labels for free for unlabelled data and train unsupervised dataset in a supervised manner? We can achieve this by framing a supervised learning task in a special form to predict only a subset of information using the rest. In this way, all the information needed, both inputs and labels, has been provided. This is known as self-supervised learning.
		
	\end{frame}
	
	\begin{frame}[t]{How it work?}\vspace{4pt}
		\begin{figure}
			\centering
			\includegraphics[scale=0.2]{google_semi.jpg}
			\caption{Semi and Self supervised learning (Qizhe Xie, 2019)}
		\end{figure}
	\end{frame}
	\begin{frame}[t]{Data Augmentation(Image data)}
		\begin{enumerate}
			\item Colorization
			\item Autoencoder
		\end{enumerate}
	\begin{figure}
		\centering
		\includegraphics[scale=0.7]{color.png}
		\caption{change color tone (fast.ai, 2021)}
		\includegraphics[scale=0.71]{inpainting.png}
		\caption{Autoencoder (Lilian Weng, 2019)}
	\end{figure}
	\end{frame}
	
	
	
	
	\begin{frame}[t]{Fomulation}
		$$\mathcal{L}(\theta, \eta) = \mathbb{E}_{x, \mathcal{T}}\Big[\|\mathcal{F}_\theta(\mathcal{T}(x)) - \eta_x\|_2^2\Big]$$
		$$\underset{\theta, \eta}{\text{min }} \mathcal{L}(\theta, \eta)$$
		\begin{enumerate}
			\item $\mathcal{F}$ is a network parameterized by $\theta$.
			\item $\mathcal{T}$ is the augmentation.
			\item $x$ is an image.
			\item The expectation $\mathbb{E}[\cdot]$ is over the distribution
			of images and augmentations. For the ease of analysis, here
			we use the mean squared error $\|\cdot\|^2_2$
			\item $\eta_x$ is the representation of the image $x$
			
		\end{enumerate}
	\end{frame}
	
	\begin{frame}[t]{Clustering Image with Self-Supervised Learning (Birds)}
		\begin{figure}
			\centering
			\includegraphics[scale=0.7]{birds.png}
			\caption{Embeding images on grid}
		\end{figure}
	\end{frame}

	\begin{frame}[t]{Clustering Earthquake Source with Self-Supervised Learning}
		\begin{figure}
			\includegraphics[scale=0.5]{self.png}
			\caption{self-supervised learning cluster local and teleseismic (S. Mostafa Mousavi, 2019)}
		\end{figure}
	\end{frame}

	\begin{frame}[t]{Why Graph and Self-Supervised?}
	\begin{enumerate}
		\item Resolve Imbalanced data problem
		\seti
	\end{enumerate}
	\begin{figure}
		\includegraphics[scale=0.3]{result.png}
		\caption{SSL and imbalanced data (Yuzhe Yang, 2020)}
	\end{figure}
	\end{frame}

	\begin{frame}[t]{Why Graph and Self-Supervised?}
		\begin{enumerate}
			\conti
			\item Represent Temporal and Spatial data
			\seti
		\end{enumerate}
	\begin{figure}
		\includegraphics[scale=0.3]{web.png}
		\caption{web traffic prediction (GNN application example)}
	\end{figure}
	\end{frame}

	\begin{frame}[t]{Why Graph and Self-Supervised?}
		\begin{enumerate}
			\conti
			\item Self-supervised Training of Graph Convolutional Networks

		\end{enumerate}
		\begin{figure}
			\includegraphics[scale=0.4]{self_graph.png}
			\caption{Self-supervised Training of Graph Convolutional Networks model (Qikui Zhu, 2020)}
		\end{figure}
	\end{frame}

	\begin{frame}[standout]
		Q/A
	\end{frame}
\end{document}